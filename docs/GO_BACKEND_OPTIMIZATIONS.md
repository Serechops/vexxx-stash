# Go Backend Performance Optimizations

> **Created:** January 21, 2026  
> **Last Updated:** January 21, 2026  
> **Status:** ‚úÖ Complete  
> **Estimated Total Impact:** 25-40% faster API responses, 20-35% better DB performance

---

## Progress Tracker

| # | Optimization | Priority | Effort | Status | PR |
|---|-------------|----------|--------|--------|-----|
| 1 | sync.Pool for Scene Buffers | üî¥ High | Low | ‚úÖ **Integrated** | - |
| 2 | sync.Pool for Byte Buffers | üî¥ High | Low | ‚úÖ **Integrated** | - |
| 3 | errgroup for Batch Processing | üî¥ High | Medium | ‚úÖ **Integrated** | - |
| 4 | singleflight for Loaders | üî¥ High | Low | ‚úÖ **Integrated** | - |
| 5 | Pre-allocated Slices in Hot Paths | üü° Medium | Low | ‚úÖ **Integrated** | - |
| 6 | strings.Builder Optimization | üü° Medium | Low | ‚úÖ **Integrated** | - |
| 7 | JSON Encoder Pooling | üü° Medium | Medium | ‚úÖ Completed | - |
| 8 | LRU Cache for Entities | üî¥ High | Medium | ‚úÖ **Integrated** | - |
| 9 | Database Timeout Contexts | üü° Medium | Low | ‚úÖ **Integrated** | - |
| 10 | SQLite PRAGMA Optimizations | üü° Medium | Low | ‚úÖ **Already Implemented** | - |
| 11 | FFmpeg Args Builder | üü¢ Low | Low | ‚è≠Ô∏è Skipped (already exists) | - |
| 12 | pprof HTTP Endpoints | üü¢ Low | Low | ‚úÖ **Integrated** | - |
| 13 | expvar Metrics | üü¢ Low | Low | ‚úÖ **Integrated** | - |
| 14 | io.Copy Buffer Pooling | üü° Medium | Low | ‚úÖ **Integrated** | - |
| 15 | HW Accel Detection Cache | üü¢ Low | Medium | ‚úÖ **Integrated** | - |

---

## Benchmark Results (January 21, 2026)

### LRU Cache Performance
```
BenchmarkLRUGet-24              60,245,802     19.26 ns/op    0 B/op    0 allocs/op
BenchmarkLRUSet-24              58,526,306     19.59 ns/op    0 B/op    0 allocs/op
BenchmarkLRUGetSet-24           90,268,322     13.23 ns/op    0 B/op    0 allocs/op
```
**Result:** Zero allocations per operation!

### Buffer Pool Performance
```
BenchmarkGetPutBuffer-24        99,884,300     12.03 ns/op       0 B/op    0 allocs/op
BenchmarkNewBuffer-24           41,422,875     29.02 ns/op       0 B/op    0 allocs/op
BenchmarkCopyBuffered-24         2,781,733    430.7 ns/op       48 B/op    1 allocs/op
BenchmarkIoCopy-24                 377,305   3484   ns/op    32864 B/op    3 allocs/op
```
**Result:** CopyBuffered is **8x faster** with **685x less memory allocation**!

### Entity Slice Pool Performance
```
BenchmarkIntSlicePool-24       163,743,369      7.306 ns/op      0 B/op    0 allocs/op
```
**Result:** Zero allocation int slice reuse!

### Batch Processing Performance
```
BenchmarkBatchExec-24               610,596     1981 ns/op       0 B/op    0 allocs/op
BenchmarkBatchExecConcurrent-24     199,554     5755 ns/op    1328 B/op   25 allocs/op
```
**Note:** Sequential is faster for trivial work; concurrent is for I/O-bound operations.

---

## Files Created/Modified (January 21, 2026)

### New Infrastructure Files
| File | Description |
|------|-------------|
| `pkg/utils/buffer_pool.go` | sync.Pool utilities for small/medium/large buffers |
| `pkg/utils/buffer_pool_test.go` | 12 tests + 4 benchmarks for buffer pools |
| `pkg/utils/copy.go` | Pooled io operations: CopyBuffered, ReadAllBuffered |
| `pkg/utils/json_pool.go` | Pooled JSON encoding/decoding |
| `pkg/cache/lru.go` | Generic LRU[K,V] cache with TTL support |
| `pkg/cache/lru_test.go` | 12 tests + 3 benchmarks for LRU cache |
| `pkg/cache/entity_cache.go` | Combined LRU + singleflight EntityCache[T] |
| `pkg/singleflight/singleflight.go` | Generic singleflight wrappers for entities |
| `pkg/metrics/metrics.go` | expvar-based metrics collection with Snapshot() |
| `pkg/sqlite/cache.go` | Database-level entity cache integration |
| `pkg/sqlite/pools.go` | Entity slice pools (Scene, Performer, Tag, etc.) |
| `pkg/sqlite/pools_test.go` | 7 tests + 4 benchmarks for slice pools |
| `pkg/sqlite/batch_test.go` | 10 tests + 3 benchmarks for batch processing |
| `internal/api/debug/debug.go` | pprof and metrics HTTP endpoints |

### Modified Files
| File | Change |
|------|--------|
| `pkg/sqlite/database.go` | Added `Caches *EntityCaches` field, `InitCaches()`, `InvalidateCache()` |
| `pkg/sqlite/tx.go` | Added metrics recording via `metrics.RecordDBQuery()` in `logSQL()` |
| `pkg/sqlite/batch.go` | Added `batchExecConcurrent()`, `parallelProcess()`, `WorkerPool`, `MapConcurrent()` |
| `pkg/sqlite/blob/fs.go` | Changed to use `utils.ReadAllBuffered()` for blob reads |
| `internal/static/embed.go` | Changed to use `utils.ReadAllBuffered()` for static file reads |
| `internal/api/images.go` | Changed to use `utils.ReadAllBuffered()` for performer images |

### Removed Files
| File | Reason |
|------|--------|
| `pkg/ffmpeg/args_builder.go` | Redundant - `pkg/ffmpeg/options.go` already has fluent `Args` type |

### Already Optimized (discovered)
| File | Optimization |
|------|-------------|
| `pkg/sqlite/database.go` | SQLite PRAGMA: 64MB cache, mmap 30GB, temp_store=memory |

---

## Week 1 Targets

### 1. sync.Pool for Scene Buffers
**File:** `pkg/sqlite/scene.go`  
**Impact:** 20-30% reduction in GC pressure  
**Status:** ‚¨ú Not Started

#### Implementation
```go
var sceneBufferPool = sync.Pool{
    New: func() interface{} {
        return make([]*models.Scene, 0, 100)
    },
}

// Usage in getMany()
func (qb *SceneStore) getMany(ctx context.Context, q *goqu.SelectDataset) ([]*models.Scene, error) {
    ret := sceneBufferPool.Get().([]*models.Scene)[:0]
    // ... existing logic using ret
    // Note: caller must copy results if storing, then return buffer to pool
}
```

#### Files to Modify
- [ ] `pkg/sqlite/scene.go` - Add pool, modify getMany()
- [ ] `pkg/sqlite/performer.go` - Similar pattern
- [ ] `pkg/sqlite/gallery.go` - Similar pattern
- [ ] `pkg/sqlite/image.go` - Similar pattern

---

### 2. sync.Pool for Byte Buffers
**File:** `pkg/utils/buffer_pool.go` (new)  
**Impact:** 10-15% faster image/video operations  
**Status:** ‚¨ú Not Started

#### Implementation
```go
package utils

import (
    "bytes"
    "sync"
)

var (
    // SmallBufferPool for buffers up to 4KB
    SmallBufferPool = sync.Pool{
        New: func() interface{} {
            return bytes.NewBuffer(make([]byte, 0, 4*1024))
        },
    }

    // MediumBufferPool for buffers up to 32KB
    MediumBufferPool = sync.Pool{
        New: func() interface{} {
            return bytes.NewBuffer(make([]byte, 0, 32*1024))
        },
    }

    // LargeBufferPool for buffers up to 256KB
    LargeBufferPool = sync.Pool{
        New: func() interface{} {
            return bytes.NewBuffer(make([]byte, 0, 256*1024))
        },
    }
)

func GetBuffer(size int) *bytes.Buffer {
    if size <= 4*1024 {
        return SmallBufferPool.Get().(*bytes.Buffer)
    } else if size <= 32*1024 {
        return MediumBufferPool.Get().(*bytes.Buffer)
    }
    return LargeBufferPool.Get().(*bytes.Buffer)
}

func PutBuffer(buf *bytes.Buffer, size int) {
    buf.Reset()
    if size <= 4*1024 {
        SmallBufferPool.Put(buf)
    } else if size <= 32*1024 {
        MediumBufferPool.Put(buf)
    } else {
        LargeBufferPool.Put(buf)
    }
}
```

#### Files to Modify
- [ ] `pkg/utils/buffer_pool.go` - Create new file
- [ ] `pkg/ffmpeg/transcoder/*.go` - Use buffer pool
- [ ] `internal/api/images.go` - Use buffer pool

---

### 3. errgroup for Concurrent Batch Processing
**File:** `internal/manager/task_*.go`  
**Impact:** 2-3x speedup for batch operations  
**Status:** ‚¨ú Not Started

#### Implementation
```go
import "golang.org/x/sync/errgroup"

func (t *GenerateTask) processScenesConcurrently(ctx context.Context, scenes []*models.Scene) error {
    g, ctx := errgroup.WithContext(ctx)
    g.SetLimit(runtime.NumCPU())
    
    for _, scene := range scenes {
        scene := scene // capture
        g.Go(func() error {
            return t.processScene(ctx, scene)
        })
    }
    return g.Wait()
}
```

#### Files to Modify
- [ ] `go.mod` - Add `golang.org/x/sync` dependency
- [ ] `internal/manager/task_generate.go` - Use errgroup
- [ ] `internal/manager/task_scan.go` - Use errgroup
- [ ] `internal/manager/task_autotag.go` - Use errgroup

---

### 4. singleflight for Duplicate Request Suppression
**File:** `pkg/sqlite/singleflight.go` (new)  
**Impact:** 50-80% reduction in duplicate queries  
**Status:** ‚¨ú Not Started

#### Implementation
```go
package sqlite

import (
    "context"
    "fmt"
    "golang.org/x/sync/singleflight"
    "github.com/stashapp/stash/pkg/models"
)

type CachedSceneStore struct {
    *SceneStore
    sf singleflight.Group
}

func NewCachedSceneStore(store *SceneStore) *CachedSceneStore {
    return &CachedSceneStore{SceneStore: store}
}

func (c *CachedSceneStore) Find(ctx context.Context, id int) (*models.Scene, error) {
    key := fmt.Sprintf("scene:%d", id)
    v, err, _ := c.sf.Do(key, func() (interface{}, error) {
        return c.SceneStore.Find(ctx, id)
    })
    if err != nil {
        return nil, err
    }
    if v == nil {
        return nil, nil
    }
    return v.(*models.Scene), nil
}
```

#### Files to Modify
- [ ] `pkg/sqlite/singleflight.go` - Create new file
- [ ] `pkg/sqlite/scene.go` - Wrap with singleflight
- [ ] `pkg/sqlite/performer.go` - Wrap with singleflight
- [ ] `pkg/sqlite/studio.go` - Wrap with singleflight

---

## Week 2 Targets

### 5. Pre-allocated Slices in Hot Paths
**Files:** `pkg/ffmpeg/*.go`  
**Impact:** 5-10% reduction in allocations  
**Status:** ‚¨ú Not Started

#### Before
```go
args = append(args, "-i", input)
args = append(args, "-ss", fmt.Sprint(seconds))
args = append(args, "-t", fmt.Sprint(duration))
```

#### After
```go
args := make([]string, 0, 30) // pre-allocate
args = append(args, "-i", input, "-ss", fmt.Sprint(seconds), "-t", fmt.Sprint(duration))
```

#### Files to Modify
- [ ] `pkg/ffmpeg/stream_transcode.go`
- [ ] `pkg/ffmpeg/stream_segmented.go`
- [ ] `pkg/ffmpeg/options.go`
- [ ] `pkg/ffmpeg/transcoder/transcode.go`

---

### 6. strings.Builder Optimization
**Files:** Various path/URL construction  
**Impact:** 10-20% faster string operations  
**Status:** ‚¨ú Not Started

#### Implementation
```go
func buildPath(parts ...string) string {
    var b strings.Builder
    totalLen := len(parts) - 1 // for separators
    for _, p := range parts {
        totalLen += len(p)
    }
    b.Grow(totalLen)
    
    for i, p := range parts {
        if i > 0 {
            b.WriteByte('/')
        }
        b.WriteString(p)
    }
    return b.String()
}
```

#### Files to Modify
- [ ] `internal/api/urlbuilders/*.go`
- [ ] `pkg/fsutil/path.go`
- [ ] `pkg/sqlite/scene.go` - Path construction

---

### 7. JSON Encoder Pooling
**File:** `pkg/utils/json_pool.go` (new)  
**Impact:** 15-25% faster API responses  
**Status:** ‚¨ú Not Started

#### Implementation
```go
package utils

import (
    "bytes"
    "encoding/json"
    "io"
    "sync"
)

var jsonBufferPool = sync.Pool{
    New: func() interface{} {
        return bytes.NewBuffer(make([]byte, 0, 4096))
    },
}

func MarshalJSON(v interface{}) ([]byte, error) {
    buf := jsonBufferPool.Get().(*bytes.Buffer)
    defer func() {
        buf.Reset()
        jsonBufferPool.Put(buf)
    }()
    
    enc := json.NewEncoder(buf)
    if err := enc.Encode(v); err != nil {
        return nil, err
    }
    
    // Copy result (encoder adds newline, trim it)
    result := buf.Bytes()
    if len(result) > 0 && result[len(result)-1] == '\n' {
        result = result[:len(result)-1]
    }
    return append([]byte(nil), result...), nil
}

func WriteJSON(w io.Writer, v interface{}) error {
    buf := jsonBufferPool.Get().(*bytes.Buffer)
    defer func() {
        buf.Reset()
        jsonBufferPool.Put(buf)
    }()
    
    enc := json.NewEncoder(buf)
    if err := enc.Encode(v); err != nil {
        return err
    }
    
    _, err := w.Write(buf.Bytes())
    return err
}
```

#### Files to Modify
- [ ] `pkg/utils/json_pool.go` - Create new file
- [ ] `internal/api/*.go` - Use pooled encoder where appropriate

---

## Week 3 Targets

### 8. LRU Cache for Entities
**File:** `pkg/sqlite/cache.go` (new)  
**Impact:** 30-50% faster repeated lookups  
**Status:** ‚¨ú Not Started

#### Implementation
```go
package sqlite

import (
    "context"
    "sync"
    
    lru "github.com/hashicorp/golang-lru/v2"
    "github.com/stashapp/stash/pkg/models"
)

type EntityCache[T any] struct {
    cache *lru.Cache[int, T]
    mu    sync.RWMutex
}

func NewEntityCache[T any](size int) (*EntityCache[T], error) {
    cache, err := lru.New[int, T](size)
    if err != nil {
        return nil, err
    }
    return &EntityCache[T]{cache: cache}, nil
}

func (c *EntityCache[T]) Get(id int) (T, bool) {
    c.mu.RLock()
    defer c.mu.RUnlock()
    return c.cache.Get(id)
}

func (c *EntityCache[T]) Set(id int, value T) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.cache.Add(id, value)
}

func (c *EntityCache[T]) Invalidate(id int) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.cache.Remove(id)
}

func (c *EntityCache[T]) Clear() {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.cache.Purge()
}

// CachedSceneStore wraps SceneStore with LRU cache
type CachedSceneStoreWithLRU struct {
    *SceneStore
    cache *EntityCache[*models.Scene]
}

func NewCachedSceneStoreWithLRU(store *SceneStore, cacheSize int) (*CachedSceneStoreWithLRU, error) {
    cache, err := NewEntityCache[*models.Scene](cacheSize)
    if err != nil {
        return nil, err
    }
    return &CachedSceneStoreWithLRU{
        SceneStore: store,
        cache:      cache,
    }, nil
}

func (c *CachedSceneStoreWithLRU) Find(ctx context.Context, id int) (*models.Scene, error) {
    if scene, ok := c.cache.Get(id); ok {
        return scene, nil
    }
    
    scene, err := c.SceneStore.Find(ctx, id)
    if err != nil {
        return nil, err
    }
    if scene != nil {
        c.cache.Set(id, scene)
    }
    return scene, nil
}
```

#### Dependencies
```bash
go get github.com/hashicorp/golang-lru/v2
```

#### Files to Modify
- [ ] `go.mod` - Add LRU dependency
- [ ] `pkg/sqlite/cache.go` - Create new file
- [ ] `pkg/sqlite/database.go` - Initialize caches
- [ ] `pkg/sqlite/scene.go` - Use cache
- [ ] `pkg/sqlite/performer.go` - Use cache
- [ ] `pkg/sqlite/studio.go` - Use cache
- [ ] `pkg/sqlite/tag.go` - Use cache

---

### 9. Database Timeout Contexts
**File:** `pkg/sqlite/database.go`  
**Impact:** Better resource management, prevent hung queries  
**Status:** ‚¨ú Not Started

#### Implementation
```go
const (
    DefaultQueryTimeout = 30 * time.Second
    SlowQueryThreshold  = 5 * time.Second
)

func (db *Database) QueryWithTimeout(ctx context.Context, timeout time.Duration, fn func(context.Context) error) error {
    ctx, cancel := context.WithTimeout(ctx, timeout)
    defer cancel()
    
    start := time.Now()
    err := fn(ctx)
    duration := time.Since(start)
    
    if duration > SlowQueryThreshold {
        logger.Warnf("Slow query detected: %v", duration)
    }
    
    return err
}
```

#### Files to Modify
- [ ] `pkg/sqlite/database.go` - Add timeout wrapper
- [ ] `pkg/sqlite/scene.go` - Apply to complex queries
- [ ] `pkg/txn/transaction.go` - Add timeout support

---

### 10. SQLite PRAGMA Optimizations
**File:** `pkg/sqlite/database.go`  
**Impact:** 15-25% faster complex queries  
**Status:** ‚¨ú Not Started

#### Implementation
```go
func (db *Database) applyOptimizations() error {
    pragmas := []string{
        "PRAGMA temp_store = MEMORY",
        "PRAGMA mmap_size = 268435456", // 256MB
        "PRAGMA page_size = 4096",
        "PRAGMA journal_mode = WAL",
        "PRAGMA synchronous = NORMAL",
        "PRAGMA cache_size = -64000", // 64MB (negative = KB)
        "PRAGMA busy_timeout = 5000",
        "PRAGMA foreign_keys = ON",
    }
    
    for _, pragma := range pragmas {
        if _, err := db.writeDB.Exec(pragma); err != nil {
            return fmt.Errorf("failed to apply pragma %q: %w", pragma, err)
        }
    }
    return nil
}
```

#### Files to Modify
- [ ] `pkg/sqlite/database.go` - Add PRAGMA optimizations
- [ ] `pkg/sqlite/driver.go` - Apply on connection

---

## Week 4 Targets

### 11. FFmpeg Args Builder
**File:** `pkg/ffmpeg/args_builder.go` (new)  
**Impact:** Cleaner code, fewer allocations  
**Status:** ‚¨ú Not Started

#### Implementation
```go
package ffmpeg

type ArgsBuilder struct {
    args []string
}

func NewArgsBuilder(capacity int) *ArgsBuilder {
    return &ArgsBuilder{
        args: make([]string, 0, capacity),
    }
}

func (b *ArgsBuilder) Add(args ...string) *ArgsBuilder {
    b.args = append(b.args, args...)
    return b
}

func (b *ArgsBuilder) AddIf(condition bool, args ...string) *ArgsBuilder {
    if condition {
        b.args = append(b.args, args...)
    }
    return b
}

func (b *ArgsBuilder) Input(path string) *ArgsBuilder {
    return b.Add("-i", path)
}

func (b *ArgsBuilder) SeekTo(seconds float64) *ArgsBuilder {
    return b.Add("-ss", fmt.Sprint(seconds))
}

func (b *ArgsBuilder) Duration(seconds float64) *ArgsBuilder {
    return b.Add("-t", fmt.Sprint(seconds))
}

func (b *ArgsBuilder) Output(path string) *ArgsBuilder {
    return b.Add(path)
}

func (b *ArgsBuilder) Build() []string {
    return b.args
}
```

#### Files to Modify
- [ ] `pkg/ffmpeg/args_builder.go` - Create new file
- [ ] `pkg/ffmpeg/stream_transcode.go` - Refactor to use builder
- [ ] `pkg/ffmpeg/stream_segmented.go` - Refactor to use builder

---

### 12. pprof HTTP Endpoints
**File:** `internal/api/routes_pprof.go` (new)  
**Impact:** Better debugging capabilities  
**Status:** ‚¨ú Not Started

#### Implementation
```go
//go:build debug

package api

import (
    "net/http"
    "net/http/pprof"
)

func (s *Server) registerPprofRoutes() {
    s.router.HandleFunc("/debug/pprof/", pprof.Index)
    s.router.HandleFunc("/debug/pprof/cmdline", pprof.Cmdline)
    s.router.HandleFunc("/debug/pprof/profile", pprof.Profile)
    s.router.HandleFunc("/debug/pprof/symbol", pprof.Symbol)
    s.router.HandleFunc("/debug/pprof/trace", pprof.Trace)
    s.router.Handle("/debug/pprof/heap", pprof.Handler("heap"))
    s.router.Handle("/debug/pprof/goroutine", pprof.Handler("goroutine"))
    s.router.Handle("/debug/pprof/block", pprof.Handler("block"))
    s.router.Handle("/debug/pprof/mutex", pprof.Handler("mutex"))
}
```

#### Files to Modify
- [ ] `internal/api/routes_pprof.go` - Create new file (debug build only)
- [ ] `internal/api/routes_pprof_stub.go` - Empty stub for release builds
- [ ] `internal/api/server.go` - Call registerPprofRoutes()

---

### 13. expvar Metrics
**File:** `pkg/metrics/metrics.go` (new)  
**Impact:** Better observability  
**Status:** ‚¨ú Not Started

#### Implementation
```go
package metrics

import (
    "expvar"
    "sync/atomic"
    "time"
)

var (
    // Database metrics
    DBQueriesTotal     = expvar.NewInt("db_queries_total")
    DBQueryDurationMs  = expvar.NewFloat("db_query_duration_ms")
    DBSlowQueriesTotal = expvar.NewInt("db_slow_queries_total")
    
    // API metrics
    APIRequestsTotal   = expvar.NewInt("api_requests_total")
    APIRequestDuration = expvar.NewFloat("api_request_duration_ms")
    
    // Cache metrics
    CacheHitsTotal   = expvar.NewInt("cache_hits_total")
    CacheMissesTotal = expvar.NewInt("cache_misses_total")
    
    // Job metrics
    JobsRunning   = expvar.NewInt("jobs_running")
    JobsCompleted = expvar.NewInt("jobs_completed")
    JobsFailed    = expvar.NewInt("jobs_failed")
)

type Timer struct {
    start    time.Time
    duration *expvar.Float
    counter  *expvar.Int
}

func NewTimer(duration *expvar.Float, counter *expvar.Int) *Timer {
    return &Timer{
        start:    time.Now(),
        duration: duration,
        counter:  counter,
    }
}

func (t *Timer) Done() {
    if t.counter != nil {
        t.counter.Add(1)
    }
    if t.duration != nil {
        t.duration.Set(float64(time.Since(t.start).Milliseconds()))
    }
}
```

#### Files to Modify
- [ ] `pkg/metrics/metrics.go` - Create new file
- [ ] `pkg/sqlite/database.go` - Add query metrics
- [ ] `internal/api/middleware.go` - Add request metrics
- [ ] `pkg/job/manager.go` - Add job metrics

---

### 14. io.Copy Buffer Pooling
**File:** `pkg/utils/copy.go` (new)  
**Impact:** Faster file operations  
**Status:** ‚¨ú Not Started

#### Implementation
```go
package utils

import (
    "io"
    "sync"
)

const copyBufferSize = 32 * 1024 // 32KB

var copyBufferPool = sync.Pool{
    New: func() interface{} {
        buf := make([]byte, copyBufferSize)
        return &buf
    },
}

// CopyBuffered performs io.Copy using a pooled buffer
func CopyBuffered(dst io.Writer, src io.Reader) (int64, error) {
    bufPtr := copyBufferPool.Get().(*[]byte)
    defer copyBufferPool.Put(bufPtr)
    return io.CopyBuffer(dst, src, *bufPtr)
}

// CopyN copies exactly n bytes using a pooled buffer
func CopyNBuffered(dst io.Writer, src io.Reader, n int64) (int64, error) {
    bufPtr := copyBufferPool.Get().(*[]byte)
    defer copyBufferPool.Put(bufPtr)
    return io.CopyBuffer(dst, io.LimitReader(src, n), *bufPtr)
}
```

#### Files to Modify
- [ ] `pkg/utils/copy.go` - Create new file
- [ ] `pkg/fsutil/file.go` - Use CopyBuffered
- [ ] `pkg/image/*.go` - Use CopyBuffered

---

### 15. Hardware Acceleration Detection Cache
**File:** `pkg/ffmpeg/hw_accel_cache.go` (new)  
**Impact:** Faster startup, persistent detection  
**Status:** ‚¨ú Not Started

#### Implementation
```go
package ffmpeg

import (
    "encoding/json"
    "os"
    "path/filepath"
    "sync"
    "time"
)

type HWAccelCache struct {
    mu        sync.RWMutex
    support   map[string]bool
    path      string
    lastCheck time.Time
}

type hwAccelCacheData struct {
    Support   map[string]bool `json:"support"`
    Timestamp time.Time       `json:"timestamp"`
    Version   string          `json:"version"`
}

func NewHWAccelCache(cacheDir, ffmpegVersion string) *HWAccelCache {
    c := &HWAccelCache{
        support: make(map[string]bool),
        path:    filepath.Join(cacheDir, "hw_accel_cache.json"),
    }
    c.load(ffmpegVersion)
    return c
}

func (c *HWAccelCache) load(currentVersion string) {
    c.mu.Lock()
    defer c.mu.Unlock()
    
    data, err := os.ReadFile(c.path)
    if err != nil {
        return
    }
    
    var cached hwAccelCacheData
    if err := json.Unmarshal(data, &cached); err != nil {
        return
    }
    
    // Invalidate if version changed or older than 7 days
    if cached.Version != currentVersion || time.Since(cached.Timestamp) > 7*24*time.Hour {
        return
    }
    
    c.support = cached.Support
    c.lastCheck = cached.Timestamp
}

func (c *HWAccelCache) save(version string) error {
    c.mu.RLock()
    defer c.mu.RUnlock()
    
    data := hwAccelCacheData{
        Support:   c.support,
        Timestamp: time.Now(),
        Version:   version,
    }
    
    bytes, err := json.MarshalIndent(data, "", "  ")
    if err != nil {
        return err
    }
    
    return os.WriteFile(c.path, bytes, 0644)
}

func (c *HWAccelCache) Get(codec string) (supported bool, cached bool) {
    c.mu.RLock()
    defer c.mu.RUnlock()
    
    if val, ok := c.support[codec]; ok {
        return val, true
    }
    return false, false
}

func (c *HWAccelCache) Set(codec string, supported bool) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.support[codec] = supported
}
```

#### Files to Modify
- [ ] `pkg/ffmpeg/hw_accel_cache.go` - Create new file
- [ ] `pkg/ffmpeg/ffmpeg.go` - Use cache for codec detection

---

## Benchmarking

### Before Implementation
Run these benchmarks before starting optimizations:

```bash
# Full benchmark suite
cd pkg/sqlite && go test -bench=. -benchmem -count=5 > benchmark_before.txt

# Specific benchmarks
go test -bench=BenchmarkSceneFind -benchmem -count=10 ./pkg/sqlite/
go test -bench=BenchmarkQuery -benchmem -count=10 ./pkg/sqlite/
```

### After Implementation
```bash
# Compare results
cd pkg/sqlite && go test -bench=. -benchmem -count=5 > benchmark_after.txt
benchstat benchmark_before.txt benchmark_after.txt
```

### Expected Results
| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Allocs/op (Scene Query) | ~50 | ~20 | 60% |
| ns/op (Scene Find) | ~5000 | ~3000 | 40% |
| B/op (JSON Marshal) | ~2048 | ~512 | 75% |

---

## Dependencies to Add

```bash
# Add required dependencies
go get golang.org/x/sync
go get github.com/hashicorp/golang-lru/v2
```

---

## Testing Checklist

- [ ] All existing tests pass after each optimization
- [ ] No race conditions (`go test -race ./...`)
- [ ] Memory usage stable under load
- [ ] No goroutine leaks
- [ ] Benchmark improvements verified

---

## Rollback Plan

Each optimization should be:
1. Implemented in a separate branch
2. Behind a feature flag if possible
3. Easy to revert without affecting other changes

---

## Notes

- Prioritize Week 1 items first (highest ROI)
- Run benchmarks before/after each major change
- Monitor production metrics after deployment
- Consider A/B testing for high-risk changes
